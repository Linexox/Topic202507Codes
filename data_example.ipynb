{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuRecDial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::datasets\\DuRecDial\\en_train.txt INFO ::::\n",
      "Total: 5678\n",
      "ItemType: <class 'dict'>\n",
      "ItemKeys: ['goal', 'user_profile', 'conversation', 'goal_topic_list', 'goal_type_list', 'situation', 'knowledge']\n",
      "goal: <class 'str'>\n",
      "user_profile: <class 'dict'>\n",
      "conversation: <class 'list'>\n",
      "goal_topic_list: <class 'list'>\n",
      "goal_type_list: <class 'list'>\n",
      "situation: <class 'str'>\n",
      "knowledge: <class 'list'>\n",
      "\n",
      "goal sample: [1] Q&A(Jackie Chan)-->[2] Chat about stars(Jackie Chan)-->[3] Movie recommendation(Project Eagle)-->[4]Say goodbye\n",
      "knowledge sample: [['Jackie Chan', 'Stars', 'Earth: One Amazing Day'], ['Jackie Chan', 'Stars', 'Earth: One Amazing Day'], [], ['Jackie Chan', 'Intro', 'Hong Kong movie star'], [], ['Jackie Chan', 'Intro', 'celebrities with private jets'], [], ['Project Eagle', 'Comments', \"one of the movies which you'll get tired of\"], ['Project Eagle', 'Rating', '7.4'], ['Project Eagle', 'Rating', '7.4'], [], [], [], [], [], []]\n",
      "knowledge length: 16\n",
      "conversation sample: ['[1] Who is the protagonist of Earth: One Amazing Day?', \"It's Jackie Chan.\", 'Wow, you know all about it. You are so good.', '[2] Do you like the protagonist Jackie Chan? He is a Hong Kong movie star.', 'Jackie Chan is my idol, of course.', 'He is a star who owns a private jet.', 'Wow, my idol is so cool.', '[3] Yes, but what he has now is obtained through his efforts. In addition, his films are really wonderful. I recommend Project Eagle. Some people say they will never get bored of watching it.', \"What's the reputation and rating of this movie?\", 'Good reputation, the score is 7.4.', 'Sounds good. I will have a try.', \"OK, I'm glad you like it.\", \"[4] I'll go to the cinema first.\", 'Ok, goodbye.', 'Bye!', 'Bye!']\n",
      "conversation length: 16\n",
      "\n",
      "user profile sample: {'Age Range': 'Over 50 years old', 'Name': 'Qizhen Ji', 'Residence': 'Baoding', 'Accepted food': 'Sautéed\\xa0Shredded\\xa0Pork\\xa0in\\xa0Sweet\\xa0Bean\\xa0Sauce', 'Accepted movies': ['Rumble in the Bronx', 'Earth: One Amazing Day', 'Jackie Chan: My Story'], 'Accepted Music': ['Drunken Master'], 'Rejected music': ['Strive For Happiness'], 'Gender': 'Male', 'Accepted celebrities': ['Jackie Chan', 'Leehom Wang'], 'Accepted movie': ['Traces of a Dragon: Jackie Chan & His Lost Family'], 'Reject': ['News'], 'Rejected movies': ['Chop Socky: Cinema Hong Kong'], 'Accepted POI': 'Kwonkimdo Korean Self-served BBQ and Hot Pot', 'Accepted music': ['All the Things You Never Knew'], 'Occupation': 'Retired'}\n"
     ]
    }
   ],
   "source": [
    "raw_train_data_path = \"datasets\\\\DuRecDial\\\\en_train.txt\"\n",
    "with open(raw_train_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_train_data_txt = f.readlines()\n",
    "raw_train_data = [json.loads(line) for line in raw_train_data_txt]\n",
    "\n",
    "idx = 2090\n",
    "\n",
    "print(f\"::::{raw_train_data_path} INFO ::::\")\n",
    "print(f\"Total: {len(raw_train_data)}\")\n",
    "print(f\"ItemType: {type(raw_train_data[idx])}\")\n",
    "print(f\"ItemKeys: {list(raw_train_data[idx].keys())}\")\n",
    "for key in raw_train_data[idx].keys():\n",
    "    print(f\"{key}: {type(raw_train_data[0][key])}\")\n",
    "\n",
    "print()\n",
    "print(f\"goal sample: {raw_train_data[idx]['goal']}\")\n",
    "print(f'knowledge sample: {raw_train_data[idx][\"knowledge\"]}')\n",
    "print(f'knowledge length: {len(raw_train_data[idx][\"knowledge\"])}')\n",
    "print(f'conversation sample: {raw_train_data[idx][\"conversation\"]}')\n",
    "print(f'conversation length: {len(raw_train_data[idx][\"conversation\"])}')\n",
    "# print\n",
    "\n",
    "print()\n",
    "print(f'user profile sample: {raw_train_data[idx][\"user_profile\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation types: 5\n",
      "Relation list: {'Achievement', 'Stars', 'Type', 'Intro', 'Comments'}\n",
      "Head entity types: 4\n",
      "Head entity list: ['The Stool Pigeon', 'Cecilia Cheung', 'Nicholas Tse', 'Failan']\n",
      "Tail entity types: 6\n",
      "Tail entity list: ['Outstanding Asian artists of New York China Film Festival', \"Failan presents a love tragedy isolated in different time and space, but the film does not stop at telling a sad and beautiful love. Through the shell of the sad story, the audience gets the director's deeper thinking and understanding of the human nature of life.Focusing on the spiritual core of saving and being saved, the narrative unfolds, the theme is expounded, and the blindness to reality is unveiled. The audience is touched and awakened. The director fully played the magic of the movie, disrupting the narrative time and space, intersecting the past and the present, and advancing freely following the protagonists’ emotions, making the story structure more tense and the theme and emotions more heartfelt. Although it describes the underworld, the director deliberately avoided the violence rendering and used extremely life-like methods to describe the underworld story routines such as gang struggle and group fight.\", 'Action plot Thriller', 'Left Right Love Destiny', 'The Stool Pigeon', 'Chinese dreamgirl'] ...\n"
     ]
    }
   ],
   "source": [
    "relation_set = set(\n",
    "    [\n",
    "        raw_train_data[0][\"knowledge\"][i][1]\n",
    "        for i in range(len(raw_train_data[0][\"knowledge\"]))\n",
    "        if raw_train_data[0][\"knowledge\"][i] != []\n",
    "    ]\n",
    ")\n",
    "print(f\"Relation types: {len(relation_set)}\")\n",
    "print(f\"Relation list: {relation_set}\")\n",
    "\n",
    "head_set = set(\n",
    "    [\n",
    "        raw_train_data[0][\"knowledge\"][i][0]\n",
    "        for i in range(len(raw_train_data[0][\"knowledge\"]))\n",
    "        if raw_train_data[0][\"knowledge\"][i] != []\n",
    "    ]\n",
    ")\n",
    "print(f\"Head entity types: {len(head_set)}\")\n",
    "print(f\"Head entity list: {list(head_set)[:10]}\")\n",
    "\n",
    "tail_set = set(\n",
    "    [\n",
    "        raw_train_data[0][\"knowledge\"][i][2]\n",
    "        for i in range(len(raw_train_data[0][\"knowledge\"]))\n",
    "        if raw_train_data[0][\"knowledge\"][i] != []\n",
    "    ]\n",
    ")\n",
    "print(f\"Tail entity types: {len(tail_set)}\")\n",
    "print(f\"Tail entity list: {list(tail_set)[:10]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found Cecilia Cheung-Stars-Left Right Love Destiny from uttr\n",
      "found Cecilia Cheung-Stars-Left Right Love Destiny from uttr\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m head, relation, tail \u001b[38;5;129;01min\u001b[39;00m raw_train_data[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mknowledge\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m uttr \u001b[38;5;129;01min\u001b[39;00m raw_train_data[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mconversation\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      4\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m tail \u001b[38;5;129;01min\u001b[39;00m uttr:\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for head, relation, tail in raw_train_data[0][\"knowledge\"]:\n",
    "    for uttr in raw_train_data[0][\"conversation\"]:\n",
    "        if tail in uttr:\n",
    "            print(f\"found {head}-{relation}-{tail} from uttr\")\n",
    "            total += 1\n",
    "print(f\"Total {total} entities from conv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Draw Knowledge Graph\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m()\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "## Draw Knowledge Graph\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置中文字体为黑体\n",
    "# plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "\n",
    "# plt.figure(figsize=(18, 16))\n",
    "# G = nx.DiGraph()\n",
    "# for head, relation, tail in tqdm(raw_train_data[0][\"knowledge\"]):\n",
    "#     G.add_edge(head, tail, label=relation)\n",
    "# pos = nx.spring_layout(G)\n",
    "# edge_labels = nx.get_edge_attributes(G, \"label\")\n",
    "# nx.draw(G, pos, with_labels=True, arrows=True)\n",
    "# nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
